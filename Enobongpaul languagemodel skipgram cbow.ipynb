{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Enobongpaul languagemodel skipgram/cbow.ipynb","provenance":[],"authorship_tag":"ABX9TyNU1NyRgKs4ElaNx5WJYD5d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"bhqmr0kmj3AA","executionInfo":{"status":"ok","timestamp":1658756092906,"user_tz":-120,"elapsed":3362,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}}},"outputs":[],"source":["#Import libraries\n","\n","import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch.linalg\n","import numpy as np"]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# device = \"cpu"],"metadata":{"id":"90y3StadkcjJ","executionInfo":{"status":"ok","timestamp":1658760555168,"user_tz":-120,"elapsed":580,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["Prepare data"],"metadata":{"id":"zSqWrLUMkk2B"}},{"cell_type":"code","source":["# CBOW is a window view; we are trying to infer the word in the middle.\n","CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n","\n","raw_text= \"\"\"Long Short-Term Memory (LSTM) is a recurrent neural network (RNN) architecture that has been designed\n","to address the vanishing and exploding gradient problems of conventional RNNs. Unlike feedforward neural networks,\n","RNNs have cyclic connections making them powerful for modeling sequences. \n","They have been successfully used for sequence labeling and sequence prediction tasks,\n","such as handwriting recognition, language modeling, phonetic labeling of acoustic frames. However, in contrast to the deep neural\n","networks, the use of RNNs in speech recognition has been limited to phone recognition in small scale tasks. \n","In this paper, we present novel LSTM based RNN architectures which make more effective\n","use of model parameters to train acoustic models for large vocabulary speech recognition. \n","We train and compare LSTM, RNN and DNN models at various numbers of parameters and configurations.\n","We show that LSTM models converge quickly and give state of the art speech recognition performance for relatively small sized models.\"\"\".split()\n","\n","# By deriving a set from \"raw_text\", we deduplicate the array\n","vocab = set(raw_text)\n","vocab_size = len(vocab)\n","\n","# Basic Tokenizer\n","word_to_ix = {word: i for i, word in enumerate(vocab)}\n","\n","print('Length of raw text :',len(raw_text))\n","print('Length of Vocabulary :',vocab_size)\n","print('Vocabulary words :',vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZfX68RlWkm2l","executionInfo":{"status":"ok","timestamp":1658756198252,"user_tz":-120,"elapsed":423,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}},"outputId":"c9324b2f-6128-4f38-9f61-d643b135de9d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of raw text : 152\n","Length of Vocabulary : 106\n","Vocabulary words : {'modeling', 'vocabulary', 'which', 'speech', 'tasks,', 'this', 'art', 'performance', 'RNNs.', '(LSTM)', 'quickly', 'has', 'DNN', 'sequences.', 'train', 'They', 'Long', 'scale', 'neural', 'use', 'network', 'more', 'contrast', 'recognition.', 'networks,', 'phone', 'relatively', 'novel', 'numbers', 'a', 'the', 'model', 'However,', 'for', 'deep', 'at', 'modeling,', 'powerful', 'address', 'used', 'such', 'architectures', 'based', 'LSTM,', 'we', 'Memory', 'We', 'recurrent', 'making', '(RNN)', 'vanishing', 'RNNs', 'gradient', 'have', 'labeling', 'phonetic', 'Unlike', 'LSTM', 'models', 'prediction', 'frames.', 'handwriting', 'small', 'been', 'in', 'recognition', 'connections', 'as', 'Short-Term', 'acoustic', 'exploding', 'show', 'effective', 'converge', 'parameters', 'make', 'models.', 'feedforward', 'large', 'language', 'architecture', 'that', 'and', 'present', 'compare', 'to', 'configurations.', 'conventional', 'of', 'give', 'sized', 'paper,', 'RNN', 'tasks.', 'In', 'state', 'cyclic', 'problems', 'designed', 'successfully', 'them', 'limited', 'is', 'sequence', 'recognition,', 'various'}\n"]}]},{"cell_type":"code","source":["print(vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZaQjcACWl7bN","executionInfo":{"status":"ok","timestamp":1658760564755,"user_tz":-120,"elapsed":15,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}},"outputId":"88851625-5e45-4cd1-e448-9c7a147df782"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["{'modeling', 'vocabulary', 'which', 'speech', 'tasks,', 'this', 'art', 'performance', 'RNNs.', '(LSTM)', 'quickly', 'has', 'DNN', 'sequences.', 'train', 'They', 'Long', 'scale', 'neural', 'use', 'network', 'more', 'contrast', 'recognition.', 'networks,', 'phone', 'relatively', 'novel', 'numbers', 'a', 'the', 'model', 'However,', 'for', 'deep', 'at', 'modeling,', 'powerful', 'address', 'used', 'such', 'architectures', 'based', 'LSTM,', 'we', 'Memory', 'We', 'recurrent', 'making', '(RNN)', 'vanishing', 'RNNs', 'gradient', 'have', 'labeling', 'phonetic', 'Unlike', 'LSTM', 'models', 'prediction', 'frames.', 'handwriting', 'small', 'been', 'in', 'recognition', 'connections', 'as', 'Short-Term', 'acoustic', 'exploding', 'show', 'effective', 'converge', 'parameters', 'make', 'models.', 'feedforward', 'large', 'language', 'architecture', 'that', 'and', 'present', 'compare', 'to', 'configurations.', 'conventional', 'of', 'give', 'sized', 'paper,', 'RNN', 'tasks.', 'In', 'state', 'cyclic', 'problems', 'designed', 'successfully', 'them', 'limited', 'is', 'sequence', 'recognition,', 'various'}\n"]}]},{"cell_type":"code","source":["# list out keys and values separately\n","key_list = list(word_to_ix.keys())\n","val_list = list(word_to_ix.values())"],"metadata":{"id":"3ySRjysgk3xb","executionInfo":{"status":"ok","timestamp":1658760568654,"user_tz":-120,"elapsed":838,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["creating dataset"],"metadata":{"id":"crnUDVSxmrMt"}},{"cell_type":"code","source":["# Now lets create a \"dataset\"\n","data = []\n","for i in range(CONTEXT_SIZE, len(raw_text) - CONTEXT_SIZE):\n","    context = []\n","    for j in range(CONTEXT_SIZE, 0, -1):\n","        context.append(raw_text[i - j])\n","\n","    for j in range(1, CONTEXT_SIZE + 1):\n","        context.append(raw_text[i + j])\n","        \n","    target = raw_text[i]\n","    data.append((context, target))\n","print(data[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6U6v22jtme8X","executionInfo":{"status":"ok","timestamp":1658760578462,"user_tz":-120,"elapsed":531,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}},"outputId":"f51e7040-adda-4e15-9ea9-569ad86038ac"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["[(['Long', 'Short-Term', '(LSTM)', 'is'], 'Memory'), (['Short-Term', 'Memory', 'is', 'a'], '(LSTM)'), (['Memory', '(LSTM)', 'a', 'recurrent'], 'is'), (['(LSTM)', 'is', 'recurrent', 'neural'], 'a'), (['is', 'a', 'neural', 'network'], 'recurrent')]\n"]}]},{"cell_type":"markdown","source":["create CBOW model"],"metadata":{"id":"Bue1LTfIo1x_"}},{"cell_type":"code","source":["class CBOW(nn.Module):\n","\n","    def __init__(self, vocab_size, embed_dim, context, hidden_size):\n","        super(CBOW, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_dim)\n","        self.linear = nn.Sequential(\n","            nn.Linear(context*embed_dim, hidden_size),\n","            nn.ReLU(),\n","            nn.Linear(hidden_size, vocab_size),\n","            nn.LogSoftmax(dim = -1)\n","        )\n","        \n","    def forward(self, inputs):\n","#         print(inputs.shape)\n","#         print(inputs)\n","        out = self.embedding(inputs)\n","#         print(out.shape)\n","        out = out.view(1, -1)\n","#         print(out.shape)\n","        out = self.linear(out)\n","#         print(out.shape)\n","        return out\n","    \n","    # This is what we are actually interested on\n","    def get_word_vector(self, word):\n","        out = self.embedding(word)\n","        return out"],"metadata":{"id":"DfBK9myvo52J","executionInfo":{"status":"ok","timestamp":1658760588147,"user_tz":-120,"elapsed":523,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["VOCAB_SIZE = len(vocab)\n","EMBEDD_DIM = 10\n","BATCH_SIZE = 6\n","FULL_CONTEXT_SIZE = CONTEXT_SIZE * 2\n","HIDDEN_SIZE = 256\n","\n","example_tensor = torch.randint(0, VOCAB_SIZE, [BATCH_SIZE, FULL_CONTEXT_SIZE])\n","print(example_tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9fEOR5UInC6M","executionInfo":{"status":"ok","timestamp":1658760596355,"user_tz":-120,"elapsed":494,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}},"outputId":"cd65981c-1864-4619-de60-3e1e77cb22c2"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 76,  42,  89,  22],\n","        [ 38,  41,  13, 100],\n","        [  9,  58,  29,  66],\n","        [  2,  22, 102,  20],\n","        [ 45,  25,  10, 100],\n","        [ 22,  58,  10,  83]])\n"]}]},{"cell_type":"code","source":["CBOW_embedding = nn.Embedding(VOCAB_SIZE, EMBEDD_DIM)\n","print(example_tensor.shape)\n","example_result = CBOW_embedding(example_tensor)\n","# Now we have a representation of the words in a vector of EMBEDD_DIM Dimensions\n","print(example_result.shape)\n","# example_result = torch.flatten(example_result, start_dim=1)\n","example_result = example_result.view(BATCH_SIZE, -1)\n","print(example_result.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OPLE1sg_pAsQ","executionInfo":{"status":"ok","timestamp":1658760603960,"user_tz":-120,"elapsed":525,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}},"outputId":"b79936f3-8e0d-4791-d1a1-6b6f3e424e25"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([6, 4])\n","torch.Size([6, 4, 10])\n","torch.Size([6, 40])\n"]}]},{"cell_type":"code","source":["print(\"input shape: \", EMBEDD_DIM * FULL_CONTEXT_SIZE)\n","print(\"output shape: \", HIDDEN_SIZE)\n","CBOW_hidden = nn.Linear(EMBEDD_DIM * FULL_CONTEXT_SIZE, HIDDEN_SIZE)\n","CBOW_hidden_relu = nn.ReLU()\n","example_result = CBOW_hidden(example_result)\n","example_result = CBOW_hidden_relu(example_result)\n","print(example_result.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0vieTEZtpKa-","executionInfo":{"status":"ok","timestamp":1658760606841,"user_tz":-120,"elapsed":409,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}},"outputId":"7ab9a96f-05a1-4a6d-fd0b-290431fc293b"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["input shape:  40\n","output shape:  256\n","torch.Size([6, 256])\n"]}]},{"cell_type":"code","source":["CBOW_output = nn.Linear(HIDDEN_SIZE, VOCAB_SIZE)\n","CBOW_output_soft = nn.LogSoftmax(dim = -1)\n","example_result = CBOW_output(example_result)\n","example_result = CBOW_output_soft(example_result)\n","print(example_result.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8g9E47e3pbD7","executionInfo":{"status":"ok","timestamp":1658760615463,"user_tz":-120,"elapsed":400,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}},"outputId":"2bf93ca0-1050-47c9-811d-0ef580b6312c"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([6, 106])\n"]}]},{"cell_type":"code","source":["print(example_result[0].argmax(-1))\n","print(key_list[val_list.index(example_result[0].argmax(-1))])\n","print(example_result[0])\n","print(example_result[1].argmax(-1))\n","print(key_list[val_list.index(example_result[1].argmax(-1))])\n","print(example_result[1])\n","# print(example_result[2].argmax(-1))\n","# print(example_result[3].argmax(-1))\n","# print(example_result[4].argmax(-1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"njuhgSFApdZM","executionInfo":{"status":"ok","timestamp":1658760619193,"user_tz":-120,"elapsed":865,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}},"outputId":"7d68abe3-7bb3-4ccf-c4fd-23509ef21000"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(40)\n","such\n","tensor([-4.5712, -4.4901, -4.9160, -4.6440, -4.9757, -4.7100, -5.1163, -4.5753,\n","        -4.7635, -4.5510, -4.7088, -4.5678, -4.8451, -4.4883, -4.5544, -4.3537,\n","        -4.4998, -4.3164, -4.3987, -4.6746, -4.5824, -4.8035, -4.4392, -4.7948,\n","        -4.8199, -5.0696, -5.1145, -4.5310, -4.7439, -4.7126, -4.7040, -4.7572,\n","        -4.8012, -5.0589, -4.7325, -4.8628, -4.6117, -4.6089, -5.0876, -4.7128,\n","        -4.2631, -4.9567, -4.6783, -4.5243, -4.5995, -4.6649, -4.6193, -4.7021,\n","        -4.3589, -4.6332, -4.6557, -4.3562, -4.8026, -4.6214, -4.9967, -4.2872,\n","        -4.7037, -4.6921, -4.5436, -4.7300, -4.2698, -4.7494, -4.7447, -4.5764,\n","        -4.5991, -4.7304, -5.0402, -4.3886, -4.5067, -4.7539, -4.7784, -4.8041,\n","        -4.6357, -4.4745, -4.5036, -4.6260, -4.5046, -4.8630, -4.6755, -4.7636,\n","        -4.6512, -4.3036, -4.6592, -4.5385, -4.7848, -4.9297, -4.8805, -4.7054,\n","        -4.6074, -4.5297, -5.1102, -4.7816, -4.6892, -4.8389, -4.4032, -4.8663,\n","        -4.6802, -4.8109, -4.6527, -4.5011, -4.8344, -4.5516, -4.6484, -4.8389,\n","        -4.8819, -4.9975], grad_fn=<SelectBackward0>)\n","tensor(67)\n","as\n","tensor([-4.7818, -4.4792, -4.4268, -4.8309, -4.6224, -4.7618, -4.5903, -4.8523,\n","        -4.6646, -4.6422, -4.9466, -4.8821, -4.5388, -4.4670, -4.4911, -4.3864,\n","        -4.6391, -4.7785, -4.2308, -4.8451, -4.8484, -4.9524, -4.9628, -5.0316,\n","        -4.5832, -4.8322, -4.7376, -4.5267, -4.7930, -4.8096, -4.4608, -4.6625,\n","        -4.6315, -4.9887, -4.6670, -4.7277, -4.7762, -4.7472, -4.7626, -4.6938,\n","        -4.8593, -5.0656, -4.4521, -4.6838, -5.0181, -4.5042, -4.6385, -4.6956,\n","        -4.7364, -4.6225, -5.0405, -4.8197, -4.4543, -4.5991, -5.0734, -4.4910,\n","        -4.5576, -4.7883, -4.7358, -4.3243, -4.4023, -5.1088, -4.4425, -4.3796,\n","        -4.5966, -4.6394, -4.8193, -4.0459, -4.5670, -4.6892, -4.9182, -4.4247,\n","        -4.7468, -4.3819, -4.8585, -4.2194, -4.5297, -4.5835, -4.5987, -4.6683,\n","        -4.3888, -4.4421, -4.7749, -4.4423, -4.8403, -4.8349, -4.4394, -4.6255,\n","        -4.5076, -4.8536, -5.1026, -4.8776, -4.5872, -4.6800, -4.9536, -4.8021,\n","        -4.8823, -4.6850, -4.7968, -4.4658, -4.5547, -4.5394, -4.7009, -5.1503,\n","        -4.8144, -5.2224], grad_fn=<SelectBackward0>)\n"]}]},{"cell_type":"code","source":["# Simple helper method to transform the context to the expected int vector - tensor\n","\n","def make_context_vector(context, word_to_ix, debug=False):\n","    if debug:\n","      print(context)\n","    idxs = [word_to_ix[w] for w in context]\n","    return torch.tensor(idxs, dtype=torch.long)\n","\n","make_context_vector(data[0][0], word_to_ix, debug=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jxGIddHAqr9P","executionInfo":{"status":"ok","timestamp":1658760790752,"user_tz":-120,"elapsed":388,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}},"outputId":"3f3cec7f-58c7-4108-8556-e9e9c0350e17"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["['Long', 'Short-Term', '(LSTM)', 'is']\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([ 16,  68,   9, 102])"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["def train(model, epochs, data, optimizer, loss_fn):\n","    model.train()\n","    losses = []\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for context, target in data:\n","\n","            # Prepare inputs and targets \n","            context_idxs = make_context_vector(context, word_to_ix)\n","            context_idxs = context_idxs.to(device)\n","            target_id = make_context_vector([target], word_to_ix)\n","            target_id = target_id.to(device)\n","\n","            # Do not accumulate \n","            model.zero_grad()\n","\n","            # Step 3. Run the forward pass\n","            log_probs = model(context_idxs)\n","    #         break\n","\n","            # Step 4. Compute your loss function.\n","            loss = loss_fn(log_probs, target_id)\n","\n","    #         loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n","\n","            # Step 5. Do the backward pass and update the gradient\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Get the Python number from a 1-element Tensor by calling tensor.item()\n","            total_loss += loss.item()\n","        losses.append(total_loss)\n","    return losses"],"metadata":{"id":"1dZ2Axdvq55M","executionInfo":{"status":"ok","timestamp":1658760638826,"user_tz":-120,"elapsed":392,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["VOCAB_SIZE = len(vocab)\n","EMBEDD_DIM = 10\n","BATCH_SIZE = 6\n","FULL_CONTEXT_SIZE = CONTEXT_SIZE * 2\n","HIDDEN_SIZE = 256\n","\n","loss_function = nn.NLLLoss() # Because we are using Log_softmax\n","model = CBOW(vocab_size, EMBEDD_DIM, FULL_CONTEXT_SIZE, HIDDEN_SIZE)\n","model = model.to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.001)\n","\n","losses = train(model, 100, data, optimizer, loss_function)\n","model.eval()\n","\n","print(losses)  # The loss decreased every iteration over the training data!"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PSmJwl5mrFh8","executionInfo":{"status":"ok","timestamp":1658760770276,"user_tz":-120,"elapsed":10689,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}},"outputId":"4353f568-49cd-4cbe-a78b-6be7caf2cdf5"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["[694.9155240058899, 687.7885828018188, 680.7643623352051, 673.8368592262268, 666.9971764087677, 660.2417123317719, 653.5664665699005, 646.9686319828033, 640.4414632320404, 633.981306552887, 627.5825419425964, 621.2449505329132, 614.9628708362579, 608.7338593006134, 602.5551338195801, 596.4200174808502, 590.3236186504364, 584.2661881446838, 578.2428784370422, 572.2481138706207, 566.2771768569946, 560.3262183666229, 554.3945150375366, 548.4782063961029, 542.5740841627121, 536.6808401346207, 530.794450044632, 524.9121680259705, 519.0319414138794, 513.152193903923, 507.2723559141159, 501.38893365859985, 495.5020614862442, 489.6112332344055, 483.7154550552368, 477.81189143657684, 471.9032258987427, 465.9856730699539, 460.0601872205734, 454.12520921230316, 448.1791104078293, 442.2268294095993, 436.26587212085724, 430.2998768091202, 424.3313487172127, 418.3587952852249, 412.3818310499191, 406.40055698156357, 400.41673988103867, 394.43248891830444, 388.44926220178604, 382.46931463479996, 376.49037754535675, 370.5203188061714, 364.55740559101105, 358.6027045249939, 352.6580360531807, 346.7265591621399, 340.80963814258575, 334.90595984458923, 329.01667726039886, 323.14453625679016, 317.2916130423546, 311.46020579338074, 305.6547308564186, 299.8708249628544, 294.11643531918526, 288.39180678129196, 282.6982977092266, 277.0417566001415, 271.4206700325012, 265.8401839733124, 260.30112332105637, 254.80803015828133, 249.36272618174553, 243.96462339162827, 238.6182996928692, 233.32417884469032, 228.08976298570633, 222.90921688079834, 217.79385474324226, 212.74338233470917, 207.75394421815872, 202.83356615900993, 197.98144656419754, 193.19906648993492, 188.4948986172676, 183.86338239908218, 179.3108852505684, 174.83747574687004, 170.44473204016685, 166.13158309459686, 161.9019873738289, 157.7556509822607, 153.69470670819283, 149.71922321617603, 145.8296496719122, 142.02701650559902, 138.31245976686478, 134.6844933182001]\n"]}]},{"cell_type":"code","source":["# list out keys and values separately\n","key_list = list(word_to_ix.keys())\n","val_list = list(word_to_ix.values())"],"metadata":{"id":"VTGeB6GetLBL","executionInfo":{"status":"ok","timestamp":1658760664684,"user_tz":-120,"elapsed":578,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["def similarity_cbow(word_1, word_2):\n","    \n","    # test word similarity\n","    print(word_1)\n","    print(word_2)\n","    w1_id = torch.tensor(word_to_ix[word_1], dtype=torch.long)\n","    w2_id = torch.tensor(word_to_ix[word_2], dtype=torch.long)\n","    w1_id = w1_id.to(device)\n","    w2_id = w2_id.to(device)\n","    \n","    word_1_vec = model.get_word_vector(w1_id)\n","    word_2_vec = model.get_word_vector(w2_id)\n","    \n","    # The norm of a vector (1D-matrix) is the square root of the sum of all the squared values within the vector.\n","    print(math.sqrt(torch.square(word_1_vec).sum()))    \n","    print(torch.linalg.norm(word_1_vec))\n","    print(torch.linalg.norm(word_2_vec))\n","    print(word_1_vec.dot(word_2_vec))\n","    \n","    word_distance = torch.linalg.norm(word_1_vec - word_2_vec)\n","    print(\"Distance between '{}' & '{}' : {:0.4f}\".format(word_1, word_2, word_distance))\n","    word_similarity = (word_1_vec.dot(word_2_vec) / (torch.linalg.norm(word_1_vec) * torch.linalg.norm(word_2_vec)))\n","    print(\"Similarity between '{}' & '{}' : {:0.4f}\".format(word_1, word_2, word_similarity))"],"metadata":{"id":"gtk-dgljteYJ","executionInfo":{"status":"ok","timestamp":1658760667691,"user_tz":-120,"elapsed":521,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["similarity_cbow(\"neural\", \"network\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hVUsg-nJtnRl","executionInfo":{"status":"ok","timestamp":1658760675695,"user_tz":-120,"elapsed":446,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}},"outputId":"9279473b-34d7-46c7-cf0f-ff334bc09eb1"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["neural\n","network\n","3.3346826842191675\n","tensor(3.3347, grad_fn=<LinalgVectorNormBackward0>)\n","tensor(2.4982, grad_fn=<LinalgVectorNormBackward0>)\n","tensor(3.7424, grad_fn=<DotBackward0>)\n","Distance between 'neural' & 'network' : 3.1427\n","Similarity between 'neural' & 'network' : 0.4492\n"]}]},{"cell_type":"markdown","source":["Predict middle word"],"metadata":{"id":"SJqVn-IhudRj"}},{"cell_type":"code","source":["def predict_middle_word(prev_words, post_words):\n","    prev_words = prev_words.split()\n","    post_words = post_words.split()\n","\n","    input_words= make_context_vector(prev_words + post_words, word_to_ix)\n","    input_words = input_words.to(device)\n","    output = model(input_words)\n","    out_ind = output.argmax(1)\n","#     print(word_to_ix)\n","#     out_word = word_to_ix.itos[out_ind.item()]\n","    out_word = key_list[val_list.index(out_ind.item())]\n","    print(prev_words, out_word, post_words)"],"metadata":{"id":"FR4ppD_MuglB","executionInfo":{"status":"ok","timestamp":1658758765836,"user_tz":-120,"elapsed":408,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["predict_middle_word(\"a recurrent\", \"network is\")\n","predict_middle_word(\"LSTM is\", \"recurrent neural\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SJw-8tB1urAB","executionInfo":{"status":"ok","timestamp":1658758808783,"user_tz":-120,"elapsed":403,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}},"outputId":"19aa66fa-5d09-4831-d99a-82cf41d03e9e"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["['a', 'recurrent'] neural ['network', 'is']\n","['LSTM', 'is'] a ['recurrent', 'neural']\n"]}]},{"cell_type":"markdown","source":["Exercises"],"metadata":{"id":"ui-4oKsyu8X4"}},{"cell_type":"markdown","source":["Skim Gram model"],"metadata":{"id":"ALnKuQ2wu_ih"}},{"cell_type":"code","source":["class SkipGram(nn.Module):\n","    def __init__(self, n_vocab, n_embed):\n","        super().__init__()\n","        \n","        self.embed = nn.Embedding(n_vocab, n_embed)\n","        self.output = nn.Linear(n_embed, n_vocab)\n","        self.log_softmax = nn.LogSoftmax(dim=1)\n","        self.vocab_size = n_vocab\n","    \n","    def forward(self, x):\n","        x = self.embed(x)\n","        scores = self.output(x)\n","        out = scores.view(1, -1)\n","        log_ps = self.log_softmax(out)\n","        return log_ps\n","\n","    # This is what we are actually interested on\n","    def get_word_vector_skipgram(self, word):\n","        out = self.embed(word)\n","        return out"],"metadata":{"id":"GDf-5xcHvKxF","executionInfo":{"status":"ok","timestamp":1658760686273,"user_tz":-120,"elapsed":403,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["losses = []\n","embedding_dim=10 \n","\n","model_skipgram = SkipGram(len(vocab), embedding_dim).to(device)\n","model_skipgram.eval\n","criterion = nn.NLLLoss()\n","optimizer = optim.Adam(model_skipgram.parameters(), lr=0.01)\n","losses    = train(model_skipgram, 100, data, optimizer, loss_function)\n","\n","print('Losses: ',losses)\n","print('Mean Loss: ',np.mean(losses))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jICuIEjKvwmD","executionInfo":{"status":"ok","timestamp":1658760703366,"user_tz":-120,"elapsed":11294,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}},"outputId":"005b4494-7e54-4acc-a226-54b23d3d30ce"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Losses:  [946.5228967666626, 830.6464099884033, 745.1455674171448, 666.3138654232025, 595.9658558368683, 535.750091791153, 486.99715662002563, 449.28949987888336, 421.2720048427582, 401.42221039533615, 387.8040924668312, 378.0851792693138, 370.94057777523994, 365.5768465101719, 361.4219214916229, 358.08164082467556, 355.31496150791645, 353.00439324975014, 351.06703843176365, 349.87192968279123, 350.4710729953367, 351.9245348870172, 348.5440613548835, 346.98533415829297, 344.98445374681614, 344.2727210158482, 342.95775878988206, 343.4171077106148, 342.2626666156575, 344.0949020028056, 344.78243397455645, 343.2906290794199, 340.7552293064073, 340.228663223912, 338.06291420874186, 337.7984118834138, 336.84863575559575, 336.6364579007495, 336.06705347518437, 336.0804946925491, 335.7842615917325, 336.71470846934244, 337.79788395692594, 343.9487183544254, 338.9314598895144, 338.2907630307991, 335.60152107883914, 335.72402138506277, 333.93825925395777, 333.62510053787355, 332.9628950543283, 332.6577152225036, 332.34966021068976, 332.1175876454108, 331.8819611047329, 331.7055553492846, 331.5092513835334, 331.38978227871485, 331.19390755127824, 331.16775275413966, 331.19551086449064, 332.83305494708475, 338.2707165823026, 342.7410345883618, 333.2779704811401, 333.48746593808755, 330.78636313276365, 330.41671497002244, 329.91000036895275, 329.58311120793223, 329.4109012167901, 329.2276949114166, 329.1287481756881, 328.97362689021975, 328.8638416072354, 328.718967451714, 328.64357668114826, 328.49871664866805, 328.42777982726693, 328.2642879681662, 328.1687468094751, 328.07665974739933, 327.9659925512968, 327.88464637752577, 327.80583399720365, 328.0780580432579, 330.3452863655516, 342.3283580970019, 330.8436842025203, 329.0212998553702, 327.4809145220279, 327.03376508409565, 326.9506274190826, 326.83191487343265, 326.7835336640819, 326.67622576032954, 326.5814450128637, 326.49473553246935, 326.42209117559105, 326.3281874586319]\n","Mean Loss:  364.39014534059953\n"]}]},{"cell_type":"code","source":["model_skipgram.eval"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pqrhcf7SwPvP","executionInfo":{"status":"ok","timestamp":1658760707956,"user_tz":-120,"elapsed":391,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}},"outputId":"3c2dc1c0-5c45-4551-ea43-0d94aea0a23b"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method Module.eval of SkipGram(\n","  (embed): Embedding(106, 10)\n","  (output): Linear(in_features=10, out_features=106, bias=True)\n","  (log_softmax): LogSoftmax(dim=1)\n",")>"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["def similarity_skipgram(word_1, word_2):\n","    \n","    # test word similarity\n","    print(word_1)\n","    print(word_2)\n","    w1_id = torch.tensor(word_to_ix[word_1], dtype=torch.long)\n","    w2_id = torch.tensor(word_to_ix[word_2], dtype=torch.long)\n","    w1_id = w1_id.to(device)\n","    w2_id = w2_id.to(device)\n","    \n","    word_1_vec = model_skipgram.get_word_vector_skipgram(w1_id)\n","    word_2_vec = model_skipgram.get_word_vector_skipgram(w2_id)\n","    \n","    # The norm of a vector (1D-matrix) is the square root of the sum of all the squared values within the vector.\n","    print(math.sqrt(torch.square(word_1_vec).sum()))    \n","    print(torch.linalg.norm(word_1_vec))\n","    print(torch.linalg.norm(word_2_vec))\n","    print(word_1_vec.dot(word_2_vec))\n","    \n","    word_distance = torch.linalg.norm(word_1_vec - word_2_vec)\n","    print(\"Distance between '{}' & '{}' : {:0.4f}\".format(word_1, word_2, word_distance))\n","    word_similarity = (word_1_vec.dot(word_2_vec) / (torch.linalg.norm(word_1_vec) * torch.linalg.norm(word_2_vec)))\n","    print(\"Similarity between '{}' & '{}' : {:0.4f}\".format(word_1, word_2, word_similarity))"],"metadata":{"id":"ydwABSpFxzrL","executionInfo":{"status":"ok","timestamp":1658761031050,"user_tz":-120,"elapsed":569,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["similarity_skipgram(\"neural\", \"network\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjYzYNfM3RRc","executionInfo":{"status":"ok","timestamp":1658761063409,"user_tz":-120,"elapsed":410,"user":{"displayName":"Enobong Paul","userId":"06980758758409142746"}},"outputId":"bb630d64-b3b2-43b2-ad9e-b32a724ba146"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["neural\n","network\n","3.4954553799166543\n","tensor(3.4955, grad_fn=<LinalgVectorNormBackward0>)\n","tensor(5.7821, grad_fn=<LinalgVectorNormBackward0>)\n","tensor(-5.0769, grad_fn=<DotBackward0>)\n","Distance between 'neural' & 'network' : 7.4703\n","Similarity between 'neural' & 'network' : -0.2512\n"]}]}]}